{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/logo_psa.jpg\" width=\"300\">\n",
    "\n",
    "<h1><center>Constructing SAMARA Data (2.1. SAMARA)</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/user/e587246/dco00/conf/application.yml\n",
      "/gpfs/user/e587246/dco00\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from distribution_cost.configuration import spark_config\n",
    "from distribution_cost.configuration.app import AppConfig\n",
    "from distribution_cost.configuration.data import DataConfig\n",
    "from distribution_cost.infra import oracle\n",
    "from distribution_cost.domain import kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database uri\n",
    "app_config = AppConfig()\n",
    "\n",
    "db_uri = app_config.db_uri_jdbc\n",
    "db_uri_cx_oracle = app_config.db_uri_cx_oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sites': ['PY', 'MU'],\n",
       " 'start_date': '15/01/20',\n",
       " 'end_date': '17/01/20',\n",
       " 'genr_door': 'EMON'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Config\n",
    "data_config = DataConfig()\n",
    "\n",
    "data_config.vhls_perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = data_config.vhls_perimeter[\"sites\"]\n",
    "start_date = data_config.vhls_perimeter[\"start_date\"]\n",
    "end_date = data_config.vhls_perimeter[\"end_date\"]\n",
    "genr_door = data_config.vhls_perimeter[\"genr_door\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spark session\n",
    "spark_context, spark_session = spark_config.get_spark(app_name=\"app-distribution-cost\",\n",
    "                                                      executors=4, executor_cores=4, executor_mem='16g',\n",
    "                                                      dynamic_allocation=True, max_executors=8)\n",
    "\n",
    "spark_session.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinqtvin = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtvin/\")\n",
    "df_sinqtcli = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtcli/\")\n",
    "df_sinqtver = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtver/\")\n",
    "df_sinqtfv4 = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtfv4/\")\n",
    "df_sinqtcmp = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtcmp/\")\n",
    "df_sinqtcnd = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtcnd/\")\n",
    "df_sinqtseg = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtseg/\")\n",
    "df_sinqtzds = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtzds/\")\n",
    "df_sinqtsfa = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtsfa/\")\n",
    "df_sinqtfam = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtfam/\")\n",
    "df_sinqtrub = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtrub/\")\n",
    "df_sinqtopc = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtopc/\")\n",
    "df_sinqtcma = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtcma/\")\n",
    "df_sinqtcmi = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtcmi/\")\n",
    "df_sinqtcyr = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtcyr/\")\n",
    "df_sinqtmrq = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtmrq/\")\n",
    "df_sinqtbas = spark_session.read.load(\"/user/brc10/data/standardized/sinc0/sinqtbas/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinqtvin.createOrReplaceTempView(\"df_sinqtvin\")\n",
    "df_sinqtver.createOrReplaceTempView(\"df_sinqtver\")\n",
    "df_sinqtfv4.createOrReplaceTempView(\"df_sinqtfv4\")\n",
    "df_sinqtcmp.createOrReplaceTempView(\"df_sinqtcmp\")\n",
    "df_sinqtcnd.createOrReplaceTempView(\"df_sinqtcnd\")\n",
    "df_sinqtcli.createOrReplaceTempView(\"df_sinqtcli\")\n",
    "df_sinqtseg.createOrReplaceTempView(\"df_sinqtseg\")\n",
    "df_sinqtzds.createOrReplaceTempView(\"df_sinqtzds\")\n",
    "df_sinqtsfa.createOrReplaceTempView(\"df_sinqtsfa\")\n",
    "df_sinqtfam.createOrReplaceTempView(\"df_sinqtfam\")\n",
    "df_sinqtrub.createOrReplaceTempView(\"df_sinqtrub\")\n",
    "df_sinqtopc.createOrReplaceTempView(\"df_sinqtopc\")\n",
    "df_sinqtcma.createOrReplaceTempView(\"df_sinqtcma\")\n",
    "df_sinqtcmi.createOrReplaceTempView(\"df_sinqtcmi\")\n",
    "df_sinqtcyr.createOrReplaceTempView(\"df_sinqtcyr\")\n",
    "df_sinqtmrq.createOrReplaceTempView(\"df_sinqtmrq\")\n",
    "df_sinqtbas.createOrReplaceTempView(\"df_sinqtbas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "querySAMARA = \"\"\"\n",
    "SELECT\n",
    "    SINQTVIN.CODE SINQTVIN__CODE,\n",
    "    SINQTCLI_2.CODE SINQTCLI_2__CODE,\n",
    "    SINQTCLI_2.CODE_PAYS_IMPLANT,\n",
    "    SINQTVER.CODE SINQTVER__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTVER.LIB_EN,SINQTVER.LIB_FR) \n",
    "when 'fr_FR' then SINQTVER.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTVER.LIB_ES,SINQTVER.LIB_FR)\n",
    "else SINQTVER.LIB_FR\n",
    "\n",
    "end SINQTVER__LIB,\n",
    "    Table__54.DT_FACT,\n",
    "    Table__54.DT_VD,\n",
    "    Table__54.DT_COMM_CLI_FIN_VD,\n",
    "    Table__54.DATIMM,\n",
    "    SINQTCMP.CODE SINQTCMP__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCMP.LIB_EN,SINQTCMP.LIB_FR)\n",
    "when 'fr_FR' then SINQTCMP.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCMP.LIB_ES,SINQTCMP.LIB_FR)\n",
    "else SINQTCMP.LIB_FR\n",
    "\n",
    "end SINQTCMP__LIB,\n",
    "    SINQTCND.CODE SINQTCND__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCND.LIB_EN,SINQTCND.LIB_FR)\n",
    "when 'fr_FR' then SINQTCND.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCND.LIB_ES,SINQTCND.LIB_FR)\n",
    "else SINQTCND.LIB_FR\n",
    "\n",
    "end SINQTCND__LIB,\n",
    "    SINQTCLI.CODE SINQTCLI__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCLI.LIB_EN,SINQTCLI.LIB_FR)\n",
    "when 'fr_FR' then SINQTCLI.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCLI.LIB_ES,SINQTCLI.LIB_FR)\n",
    "else SINQTCLI.LIB_FR\n",
    "\n",
    "end SINQTCLI__LIB,\n",
    "    SINQTSEG.CODE SINQTSEG__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTSEG.LIB_EN,SINQTSEG.LIB_FR)\n",
    "when 'fr_FR' then SINQTSEG.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTSEG.LIB_ES,SINQTSEG.LIB_FR)\n",
    "else SINQTSEG.LIB_FR\n",
    "\n",
    "end SINQTSEG__LIB,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTZDS.LIB_EN,SINQTZDS.LIB_FR)\n",
    "when 'fr_FR' then SINQTZDS.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTZDS.LIB_ES,SINQTZDS.LIB_FR)\n",
    "else SINQTZDS.LIB_FR\n",
    "\n",
    "end SINQTZDS__LIB,\n",
    "    SINQTSFA.CODE SINQTSFA__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTSFA.LIB_EN,SINQTSFA.LIB_FR)\n",
    "when 'fr_FR' then SINQTSFA.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTSFA.LIB_ES,SINQTSFA.LIB_FR)\n",
    "else SINQTSFA.LIB_FR\n",
    "\n",
    "end SINQTSFA__LIB,\n",
    "    SINQTFAM.CODE SINQTFAM__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTFAM.LIB_EN,SINQTFAM.LIB_FR)\n",
    "when 'fr_FR' then SINQTFAM.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTFAM.LIB_ES,SINQTFAM.LIB_FR)\n",
    "else SINQTFAM.LIB_FR\n",
    "\n",
    "end SINQTFAM__LIB,\n",
    "    SINQTRUB.CODE SINQTRUB__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then SINQTRUB.LIB_EN\n",
    "when 'fr_FR' then SINQTRUB.LIB_FR\n",
    "when 'es_SP' then SINQTRUB.LIB_ES\n",
    "else SINQTRUB.LIB_FR\n",
    "\n",
    "end SINQTRUB__LIB,\n",
    "    SINQTOPC.CODE SINQTOPC__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then SINQTOPC.LIB_EN\n",
    "when 'fr_FR' then SINQTOPC.LIB_FR\n",
    "when 'es_SP' then SINQTOPC.LIB_ES\n",
    "else SINQTOPC.LIB_FR\n",
    "\n",
    "end SINQTOPC_LIB,\n",
    "    SINQTCMA.CODE SINQTCMA__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCMA.LIB_EN,SINQTCMA.LIB_FR)\n",
    "when 'fr_FR' then SINQTCMA.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCMA.LIB_ES,SINQTCMA.LIB_FR)\n",
    "else SINQTCMA.LIB_FR\n",
    "\n",
    "end SINQTCMA__LIB,\n",
    "    SINQTCMI.CODE SINQTCMI__CODE,\n",
    "    case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCMI.LIB_EN,SINQTCMI.LIB_FR)\n",
    "when 'fr_FR' then SINQTCMI.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCMI.LIB_ES,SINQTCMI.LIB_FR)\n",
    "else SINQTCMI.LIB_FR\n",
    "\n",
    "end SINQTCMI__LIB,\n",
    "    Table__54.TYPE_FLOTTE_VD,\n",
    "    Table__54.TYPE_OPE_ESSOR,\n",
    "    Table__54.TYP_UTIL_VD,\n",
    "    Table__54.CODE_PROFESSION_VD,\n",
    "    Table__54.CODE_PROMO,\n",
    "    Table__54.CODE_PROMO2,\n",
    "    SINQTCYR.ANNEE_MOIS,\n",
    "    sum(Table__54.VOLUME_AJ) VOLUME_AJ,\n",
    "    sum(Table__54.PRIX_VENTE) PRIX_VENTE,\n",
    "    sum(Table__54.PRIX_VENTE_AJ) PRIX_VENTE_AJ,\n",
    "    sum(Table__54.PV_OPTIONS) PV_OPTIONS,\n",
    "    sum(Table__54.PV_VERSION) PV_VERSION,\n",
    "    sum(Table__54.MACOM_CONSO) MACOM_CONSO,\n",
    "    sum(Table__54.MACOM_CONSO_AJ) MACOM_CONSO_AJ,\n",
    "    sum(Table__54.MACOM_CONSO_VERSION) MACOM_CONSO_VERSION,\n",
    "    sum(Table__54.MACOM_CONSO_OPTION) MACOM_CONSO_OPTION,\n",
    "    sum(Table__54.MACOM_ENTITE) MACOM_ENTITE,\n",
    "    sum(Table__54.MACOM_ENTITE_AJ) MACOM_ENTITE_AJ,\n",
    "    sum(Table__54.MACOM_ENTITE_VERSION) MACOM_ENTITE_VERSION,\n",
    "    sum(Table__54.MACOM_ENTITE_OPTION) MACOM_ENTITE_OPTION,\n",
    "    sum(Table__54.RBCV_AJ) RBCV_AJ,\n",
    "    -- sum(Table__54.MCX_VARIABLES) MCX_VARIABLES,\n",
    "    SINQTMRQ_2.CODE SINQTMRQ_2__CODE\n",
    "FROM\n",
    "    -- df_sinqtvin SINQTVIN,--\n",
    "    -- df_sinqtcli SINQTCLI_2,--\n",
    "    -- df_sinqtver SINQTVER,--\n",
    "    df_sinqtfv4 TABLE__54,\n",
    "    -- df_sinqtcmp SINQTCMP,--\n",
    "    -- df_sinqtcnd SINQTCND,--\n",
    "    -- df_sinqtcli SINQTCLI,--\n",
    "    -- df_sinqtseg SINQTSEG,--\n",
    "    -- df_sinqtzds SINQTZDS,--\n",
    "    -- df_sinqtsfa SINQTSFA,--\n",
    "    -- df_sinqtfam SINQTFAM,--\n",
    "    -- df_sinqtrub SINQTRUB,\n",
    "    -- df_sinqtopc SINQTOPC,--\n",
    "    -- df_sinqtcma SINQTCMA,--\n",
    "    -- df_sinqtcmi SINQTCMI,--\n",
    "    -- df_sinqtcyr SINQTCYR,--\n",
    "    -- df_sinqtmrq SINQTMRQ_2,--\n",
    "    df_sinqtbas SINQTBAS,--\n",
    "    df_sinqtfam SINQTFAM_2--\n",
    "    JOIN df_sinqtcmp SINQTCMP ON Table__54.ID_ZDS=SINQTCMP.ID_ZDS and Table__54.ID_CMP=SINQTCMP.ID\n",
    "    JOIN df_sinqtcli SINQTCLI ON Table__54.ID_ZDS=SINQTCLI.ID_ZDS and Table__54.ID_SCD=SINQTCLI.ID_SCD and Table__54.ID_CLI=SINQTCLI.ID\n",
    "    JOIN df_sinqtcmi SINQTCMI ON Table__54.ID_ZDS=SINQTCMI.ID_ZDS and Table__54.ID_CMI=SINQTCMI.ID\n",
    "    --JOIN df_sinqtbas SINQTBAS ON Table__54.ID_BAS=SINQTBAS.ID\n",
    "    JOIN df_sinqtzds SINQTZDS ON Table__54.ID_ZDS=SINQTZDS.ID\n",
    "    LEFT OUTER JOIN df_sinqtrub SINQTRUB ON Table__54.ID_RUB=SINQTRUB.ID\n",
    "    JOIN df_sinqtfam SINQTFAM ON Table__54.ID_ZDS=SINQTFAM.ID_ZDS and Table__54.ID_FAM=SINQTFAM.ID\n",
    "    JOIN df_sinqtsfa SINQTSFA ON Table__54.ID_ZDS=SINQTSFA.ID_ZDS and Table__54.ID_SFA=SINQTSFA.ID\n",
    "    JOIN df_sinqtver SINQTVER ON Table__54.ID_ZDS=SINQTVER.ID_ZDS and Table__54.ID_VER=SINQTVER.ID\n",
    "    LEFT OUTER JOIN df_sinqtseg SINQTSEG ON Table__54.ID_ZDS=SINQTSEG.ID_ZDS and Table__54.ID_SEG=SINQTSEG.ID\n",
    "    JOIN df_sinqtcnd SINQTCND ON Table__54.ID_CND=SINQTCND.ID\n",
    "    JOIN df_sinqtcma SINQTCMA ON Table__54.ID_CMA=SINQTCMA.ID\n",
    "    LEFT OUTER JOIN df_sinqtopc SINQTOPC ON Table__54.ID_ZDS=SINQTOPC.ID_ZDS and Table__54.ID_OPC=SINQTOPC.ID\n",
    "    JOIN df_sinqtvin SINQTVIN ON Table__54.ID_ZDS=SINQTVIN.ID_ZDS and Table__54.ID_VIN=SINQTVIN.ID\n",
    "    JOIN df_sinqtcyr SINQTCYR ON Table__54.ID_CYC=SINQTCYR.ID\n",
    "    JOIN df_sinqtcli SINQTCLI_2 ON Table__54.ID_ZDS=SINQTCLI_2.ID_ZDS and Table__54.ID_SCD=SINQTCLI_2.ID_SCD and Table__54.ID_CLI_LIV=SINQTCLI_2.ID\n",
    "    JOIN df_sinqtmrq SINQTMRQ_2 ON SINQTFAM_2.ID_MRQ_COM=SINQTMRQ_2.ID and Table__54.ID_ZDS=SINQTFAM_2.ID_ZDS and Table__54.ID_FAM=SINQTFAM_2.ID    \n",
    "\n",
    "WHERE   ( Table__54.DT_VD BETWEEN TO_DATE('01/01/2019', 'dd/MM/yyyy') AND TO_DATE('30/06/2019', 'dd/MM/yyyy'))\n",
    "    AND ( SINQTBAS.CODE  =  'LA' AND SINQTCLI_2.CODE_PAYS_IMPLANT  IN  ( 'FR','DE','PT','BE','IT','ES','GB','NL','PL','AT'  ) AND ( SINQTBAS.CODE != 'EA'  ))\n",
    "GROUP BY\n",
    "  SINQTVIN.CODE, \n",
    "  SINQTCLI_2.CODE, \n",
    "  SINQTCLI_2.CODE_PAYS_IMPLANT, \n",
    "  SINQTVER.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTVER.LIB_EN,SINQTVER.LIB_FR)\n",
    "when 'fr_FR' then SINQTVER.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTVER.LIB_ES,SINQTVER.LIB_FR)\n",
    "else SINQTVER.LIB_FR\n",
    "\n",
    "end, \n",
    "  Table__54.DT_FACT, \n",
    "  Table__54.DT_VD, \n",
    "  Table__54.DT_COMM_CLI_FIN_VD, \n",
    "  Table__54.DATIMM, \n",
    "  SINQTCMP.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCMP.LIB_EN,SINQTCMP.LIB_FR)\n",
    "when 'fr_FR' then SINQTCMP.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCMP.LIB_ES,SINQTCMP.LIB_FR)\n",
    "else SINQTCMP.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTCND.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCND.LIB_EN,SINQTCND.LIB_FR)\n",
    "when 'fr_FR' then SINQTCND.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCND.LIB_ES,SINQTCND.LIB_FR)\n",
    "else SINQTCND.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTCLI.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCLI.LIB_EN,SINQTCLI.LIB_FR)\n",
    "when 'fr_FR' then SINQTCLI.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCLI.LIB_ES,SINQTCLI.LIB_FR)\n",
    "else SINQTCLI.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTSEG.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTSEG.LIB_EN,SINQTSEG.LIB_FR)\n",
    "when 'fr_FR' then SINQTSEG.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTSEG.LIB_ES,SINQTSEG.LIB_FR)\n",
    "else SINQTSEG.LIB_FR\n",
    "\n",
    "end, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTZDS.LIB_EN,SINQTZDS.LIB_FR)\n",
    "when 'fr_FR' then SINQTZDS.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTZDS.LIB_ES,SINQTZDS.LIB_FR)\n",
    "else SINQTZDS.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTSFA.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTSFA.LIB_EN,SINQTSFA.LIB_FR)\n",
    "when 'fr_FR' then SINQTSFA.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTSFA.LIB_ES,SINQTSFA.LIB_FR)\n",
    "else SINQTSFA.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTFAM.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTFAM.LIB_EN,SINQTFAM.LIB_FR)\n",
    "when 'fr_FR' then SINQTFAM.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTFAM.LIB_ES,SINQTFAM.LIB_FR)\n",
    "else SINQTFAM.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTRUB.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then SINQTRUB.LIB_EN\n",
    "when 'fr_FR' then SINQTRUB.LIB_FR\n",
    "when 'es_SP' then SINQTRUB.LIB_ES\n",
    "else SINQTRUB.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTOPC.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then SINQTOPC.LIB_EN\n",
    "when 'fr_FR' then SINQTOPC.LIB_FR\n",
    "when 'es_SP' then SINQTOPC.LIB_ES\n",
    "else SINQTOPC.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTCMA.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCMA.LIB_EN,SINQTCMA.LIB_FR)\n",
    "when 'fr_FR' then SINQTCMA.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCMA.LIB_ES,SINQTCMA.LIB_FR)\n",
    "else SINQTCMA.LIB_FR\n",
    "\n",
    "end, \n",
    "  SINQTCMI.CODE, \n",
    "  case 'fr_FR'\n",
    "when 'en_GB' then nvl(SINQTCMI.LIB_EN,SINQTCMI.LIB_FR)\n",
    "when 'fr_FR' then SINQTCMI.LIB_FR\n",
    "when 'es_SP' then nvl(SINQTCMI.LIB_ES,SINQTCMI.LIB_FR)\n",
    "else SINQTCMI.LIB_FR\n",
    "\n",
    "end, \n",
    "  Table__54.TYPE_FLOTTE_VD, \n",
    "  Table__54.TYPE_OPE_ESSOR, \n",
    "  Table__54.TYP_UTIL_VD, \n",
    "  Table__54.CODE_PROFESSION_VD, \n",
    "  Table__54.CODE_PROMO, \n",
    "  Table__54.CODE_PROMO2, \n",
    "  SINQTCYR.ANNEE_MOIS, \n",
    "  SINQTMRQ_2.CODE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSAMARA = spark_session.sql(querySAMARA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10072216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSAMARA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o156.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 62 tasks (1031.2 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply$mcI$sp(Dataset.scala:3195)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3192)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3192)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:3225)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3192)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-69f5bcdd5c88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfSAMARA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#dfSAMARA.columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1964\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1966\u001b[0;31m             \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dco00/.venv3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dco00/.venv3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o156.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 62 tasks (1031.2 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply$mcI$sp(Dataset.scala:3195)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3192)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3192)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:3225)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3192)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "dfSAMARA.toPandas().Head(10)\n",
    "#dfSAMARA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c6d5fb2ce117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfSAMARA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \"\"\"\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dco00/.venv3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/dco00/.venv3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dco00/.venv3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/soft/python3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfSAMARA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIBELLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MANGUALDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENNES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEVEL NORD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MIZUSHIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VILLAVERDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SEVEL-VAL DI SANGRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MULHOUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VIGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KOLIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LIBELLE\n",
       "0            MANGUALDE\n",
       "1                 None\n",
       "2               RENNES\n",
       "3           SEVEL NORD\n",
       "4            MIZUSHIMA\n",
       "5           VILLAVERDE\n",
       "6  SEVEL-VAL DI SANGRO\n",
       "7             MULHOUSE\n",
       "8                 VIGO\n",
       "9                KOLIN"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSAMARA.select(\"\").distinct().toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSAMARA = dfSAMARA.drop(\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
