{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/logo_psa.jpg\" width=\"300\">\n",
    "\n",
    "<h1><center>Constructing MADAX Data</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from distribution_cost.configuration import spark_config\n",
    "from distribution_cost.configuration.app import AppConfig\n",
    "from distribution_cost.configuration.data import DataConfig\n",
    "from distribution_cost.infra import oracle\n",
    "from distribution_cost.domain import kpis\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to Exadata (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database uri\n",
    "app_config = AppConfig()\n",
    "db_uri = app_config.db_uri_jdbc\n",
    "db_uri_cx_oracle = app_config.db_uri_cx_oracle\n",
    "\n",
    "# Data Config\n",
    "data_config = DataConfig()\n",
    "\n",
    "data_config.vhls_perimeter\n",
    "\n",
    "sites = data_config.vhls_perimeter[\"sites\"]\n",
    "start_date = data_config.vhls_perimeter[\"start_date\"]\n",
    "end_date = data_config.vhls_perimeter[\"end_date\"]\n",
    "genr_door = data_config.vhls_perimeter[\"genr_door\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create spark session\n",
    "# spark_context, spark_session = spark_config.get_spark(app_name=\"app-distribution-cost\",\n",
    "#                                                       executors=4, executor_cores=4, executor_mem='16g',\n",
    "#                                                       dynamic_allocation=True, max_executors=8)\n",
    "\n",
    "# spark_session.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")\n",
    "# spark_session.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\") \n",
    "\n",
    "\n",
    "# Create spark session\n",
    "spark_context, spark_session = spark_config.get_spark(app_name=\"app-reduce-brc10sinqtfv4\",\n",
    "                                                      executors=3, executor_cores=5, executor_mem='8g',\n",
    "                                                      dynamic_allocation=True, max_executors=8)\n",
    "\n",
    "spark_session.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")\n",
    "# spark_session.conf.set(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the tables from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbvqtcdc = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtcdc/\")\n",
    "df_rbvqttxm_arc = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqttxm_arc/\")\n",
    "df_rbvqtfll = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtfll/\")\n",
    "df_rbvqttff = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqttff/\")\n",
    "df_rbvqtlm1 = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtlm1/\")\n",
    "df_rbvqtveh = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtveh/\")\n",
    "df_rbvqttut = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqttut/\")\n",
    "df_rbvqtcco = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtcco/\")\n",
    "df_rbvqtcaf = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtcaf/\")\n",
    "df_rbvqtm10 = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtm10/\")\n",
    "df_rbvqtctp = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtctp/\")\n",
    "df_rbvqtfam = spark_session.read.load(\"/user/brc06/data/standardized/bds00/rbvqtfam/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbvqtcdc.createOrReplaceTempView(\"df_rbvqtcdc\")\n",
    "df_rbvqttxm_arc.createOrReplaceTempView(\"df_rbvqttxm_arc\")\n",
    "df_rbvqtfll.createOrReplaceTempView(\"df_rbvqtfll\")\n",
    "df_rbvqttff.createOrReplaceTempView(\"df_rbvqttff\")\n",
    "df_rbvqtlm1.createOrReplaceTempView(\"df_rbvqtlm1\")\n",
    "df_rbvqtveh.createOrReplaceTempView(\"df_rbvqtveh\")\n",
    "df_rbvqttut.createOrReplaceTempView(\"df_rbvqttut\")\n",
    "df_rbvqtcco.createOrReplaceTempView(\"df_rbvqtcco\")\n",
    "df_rbvqtcaf.createOrReplaceTempView(\"df_rbvqtcaf\")\n",
    "df_rbvqtm10.createOrReplaceTempView(\"df_rbvqtm10\")\n",
    "df_rbvqtctp.createOrReplaceTempView(\"df_rbvqtctp\")\n",
    "df_rbvqtfam.createOrReplaceTempView(\"df_rbvqtfam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateFrom = \"01/08/2017\"\n",
    "dateTo = \"01/02/2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Query that constructs MADAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMADAX = \"\"\"\n",
    "(SELECT \n",
    "  RBVQTTXM_ARC.NOVIN NOVIN, \n",
    "  RBVQTTXM_ARC.DATCCLT DATCCLT, \n",
    "  RBVQTFAM_restriction.VPVU VPVU, \n",
    "  RBVQTM10.DATMEC DATMEC, \n",
    "  RBVQTTXM_ARC.TYPUTIL TYPUTIL, \n",
    "  RBVQTVEH.INDDEMO INDDEMO, \n",
    "  RBVQTM10.CO2MIXTE CO2MIXTE, \n",
    "  RBVQTTXM_ARC.HABEXTT HABEXTT, \n",
    "  RBVQTTXM_ARC.HABEXTC HABEXTC, \n",
    "  RBVQTFAM_restriction.FAMILLE FAMILLE, \n",
    "  RBVQTFAM_restriction.LIBFAMI LIBFAMI, \n",
    "  RBVQTTXM_ARC.COD_MOTOR COD_MOTOR, \n",
    "  RBVQTTXM_ARC.DATVENT DATVENT, \n",
    "  RBVQTTFF.LIBELLE_FRANCAIS LIBELLE_FRANCAIS, \n",
    "  RBVQTFAM_restriction.MARQUE MARQUE, \n",
    "  RBVQTM10.DATDEM DATDEM, \n",
    "  CASE WHEN ( RBVQTFLL.QC_FILIAL ) IN (1,63) THEN RBVQTM10.DATIMM ELSE RBVQTVEH.DATIMMAT END DATIMMAT,\n",
    "  RBVQTCDC.CODOP1 CODOP1, \n",
    "  RBVQTCDC.CODOP2 CODOP2, \n",
    "  RBVQTCDC.CODOP3 CODOP3, \n",
    "  RBVQTCDC.CODOP4 CODOP4, \n",
    "  RBVQTCDC.CODOP5 CODOP5, \n",
    "  RBVQTCDC.CODPROM CODPROM, \n",
    "  RBVQTCDC.CODPROM2 CODPROM2,\n",
    "  RBVQTCDC.REMIPOUR REMIPOUR,\n",
    "  RBVQTVEH.DATMAD DATMAD, \n",
    "  RBVQTVEH.DATEXPC DATEXPC, \n",
    "  RBVQTVEH.DATARCR DATARCR, \n",
    "  RBVQTCCO.LIBCOMBIPACK LIBCOMBIPACK, \n",
    "  RBVQTTXM_ARC.CODCPRO CODCPRO, \n",
    "  Table__129.LIBELLE LIBELLE, \n",
    "  RBVQTVEH.DATPROD DATPROD, \n",
    "  RBVQTCAF.DATMRES DATMRES \n",
    "  \n",
    "FROM \n",
    "  df_rbvqttxm_arc RBVQTTXM_ARC,\n",
    "  df_rbvqttff RBVQTTFF\n",
    "  LEFT OUTER JOIN df_rbvqtcdc RBVQTCDC ON RBVQTTXM_ARC.QI_FILIAL=RBVQTCDC.QI_FILIAL and RBVQTTXM_ARC.NUMCCLT=RBVQTCDC.NUMCCLT\n",
    "  JOIN  df_rbvqtfll RBVQTFLL ON RBVQTTFF.QI_FILIAL=RBVQTFLL.QC_FILIAL and RBVQTTXM_ARC.QI_FILIAL=RBVQTFLL.QC_FILIAL\n",
    "  LEFT OUTER JOIN df_rbvqtlm1 RBVQTLM1 ON RBVQTTXM_ARC.COD_MOTOR=RBVQTLM1.COD_MOTOR and RBVQTTXM_ARC.QI_FILIAL=RBVQTLM1.QI_FILIAL\n",
    "  LEFT OUTER JOIN df_rbvqtveh RBVQTVEH ON RBVQTTXM_ARC.QI_FILIAL=RBVQTVEH.QI_FILIAL and RBVQTTXM_ARC.NOVIN=RBVQTVEH.NOVIN\n",
    "  LEFT OUTER JOIN df_rbvqttut RBVQTTUT_TXM ON RBVQTTXM_ARC.TYPUTIL=RBVQTTUT_TXM.TYPUTIL and RBVQTTXM_ARC.QI_FILIAL=RBVQTTUT_TXM.QI_FILIAL\n",
    "  LEFT OUTER JOIN df_rbvqtcco RBVQTCCO ON RBVQTTXM_ARC.QI_FILIAL=RBVQTCCO.QI_FILIAL and RBVQTTXM_ARC.CODCPER=RBVQTCCO.CODCPER and RBVQTTXM_ARC.VERSION_CCO=RBVQTCCO.VERSION\n",
    "  LEFT OUTER JOIN df_rbvqtcaf RBVQTCAF ON RBVQTTXM_ARC.NOCAF=RBVQTCAF.NOCAF and RBVQTTXM_ARC.QI_FILIAL=RBVQTCAF.QI_FILIAL\n",
    "  LEFT OUTER JOIN df_rbvqtm10 RBVQTM10 ON RBVQTTXM_ARC.QI_FILIAL=RBVQTM10.QI_FILIAL and RBVQTTXM_ARC.NOVIN=RBVQTM10.NOVIN\n",
    "  LEFT OUTER JOIN (SELECT CODPSA as CODPSA,  MAX(LITCTP) as LIBELLE FROM df_rbvqtctp RBVQTCTP GROUP BY CODPSA ) Table__129 ON RBVQTTXM_ARC.CODCPRO=Table__129.CODPSA\n",
    "  JOIN  df_rbvqtfam RBVQTFAM_restriction ON RBVQTTXM_ARC.VPVU=RBVQTFAM_restriction.VPVU and SUBSTR(RBVQTTXM_ARC.VERS14, 1, 4)=RBVQTFAM_restriction.FAMILLE\n",
    "  \n",
    "  WHERE  RBVQTFAM_restriction.QI_FILIAL IN ('83','84')\n",
    "  AND RBVQTTFF.LIBELLE_FRANCAIS  IN  ( 'France' , 'Allemagne' , 'Portugal' , 'Autriche' , 'Belgique' , 'Italie' , 'Espagne' , 'Gde-Bretagne' , 'Pays Bas' , 'Pologne'  ) \n",
    "  AND RBVQTFAM_restriction.MARQUE  IN  ( 'AP' , 'AC', 'DS'  )  \n",
    "  AND RBVQTTXM_ARC.DATVENT BETWEEN TO_DATE('{0}', 'dd/MM/yyyy') AND TO_DATE('{1}', 'dd/MM/yyyy')\n",
    "  ORDER BY RBVQTTXM_ARC.DATVENT\n",
    "  )\n",
    "\"\"\".format(dateFrom, dateTo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMADAX = spark_session.sql(queryMADAX)\\\n",
    "    .withColumn(\"year\", F.year(F.col(\"DATVENT\")))\\\n",
    "    .withColumn(\"month\", F.month(F.col(\"DATVENT\")))\\\n",
    "    .withColumn(\"day\", F.dayofmonth(F.col(\"DATVENT\")))\\\n",
    "    .withColumn('COUNTRY', F.col('LIBELLE_FRANCAIS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promo Codes Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    codop = \"CODOP{0}\".format(str(i))\n",
    "\n",
    "    dfMADAX = dfMADAX.withColumn(codop + '_LIBELLE',\\\n",
    "                                 F.when((F.substring(codop, 1, 1) == 'C') |\\\n",
    "                                        (F.substring(codop, 1, 1) == 'D'),\\\n",
    "                                        F.col(codop).substr(F.lit(4), F.lit(F.length(F.col(codop))-5)))\\\n",
    "                                 .otherwise(F.col(codop).substr(F.lit(3), F.lit(F.length(F.col(codop))-4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping VP, VU variables from French abb. to English abb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_VpVu= {'VP':'PC','VU':'CV' }\n",
    "\n",
    "dfMADAXFinal = dfMADAX\\\n",
    "    .replace(to_replace=column_name_VpVu, subset=['VPVU'])\\\n",
    "    .withColumn('REMIPOUR', F.when(F.col('REMIPOUR')=='0', F.lit(None)).otherwise(F.col('REMIPOUR')))\\\n",
    "    .withColumn('CODPROM', F.when(F.col('CODPROM')=='0', F.lit(None)).otherwise(F.col('CODPROM')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the result in HDFS in partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMADAXFinal\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .partitionBy(\"COUNTRY\",\"MARQUE\", \"year\", \"month\")\\\n",
    "    .parquet(\"hdfs:///user/brc03/vmeca/data/raw/madax/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
